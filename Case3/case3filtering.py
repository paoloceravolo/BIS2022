# -*- coding: utf-8 -*-
"""Case3Filtering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1K6lF1zu-vzVhu33fh40fxhtvSuaDGUte

> Installing the PM4PY library
"""

# Commented out IPython magic to ensure Python compatibility.
# %pip install pm4py

import pandas as pd
import pm4py

# Preparing data

## Let's import the event log dataset in a pandas dataframe
### pm4py uses dataframe as the standard format for event logs

log_df = pd.read_csv('https://raw.githubusercontent.com/paoloceravolo/BIS2022/main/Event%20Logs/Road_Traffic_Fine_Management_Process.csv',sep=',')
log_df.rename(columns={'Case ID': 'case:concept:name', 'Complete Timestamp': 'time:timestamp', 'Activity': 'concept:name', 'Resource': 'org:resource'}, inplace=True) #change the name to a colum
# log_df = pm4py.format_dataframe(log_df, case_id='Case ID', activity_key='Activity', timestamp_key='Complete Timestamp') # DeprecatedWarning: format_dataframe is deprecated as of 2.3.0 and will be removed in 3.0.0.
# event_log = pm4py.convert_to_event_log(log_df)
# print(event_log)
# convert the 'Date' column to datetime format
log_df['time:timestamp']= pd.to_datetime(log_df['time:timestamp'])

num_events = len(log_df)
num_cases = len(log_df['case:concept:name'].unique())
print("Number of events: {}\nNumber of cases: {}".format(num_events, num_cases))

start_activities = pm4py.get_start_activities(log_df)
end_activities = pm4py.get_end_activities(log_df)
print("Start activities: {}\nEnd activities: {}".format(start_activities, end_activities))

#log_df

"""**Filtering Noise** 



1.   Activity with null time duration
2.   Incomplete cases
3.   Summarizing the log


"""

# Activity with null time duration

## Get max duration
case_durations = pm4py.get_all_case_durations(log_df)
#print(case_durations)

## Alternative way using dataframe
case_durations = log_df.groupby('case:concept:name').agg(\
Events=('case:concept:name', 'count'),\
# Multiple aggregations of the same column using pandas ...
FirstOccurence=('time:timestamp', lambda x: x.min()),
LastOccurence=('time:timestamp', lambda x: x.max()),
Duration=('time:timestamp', lambda x: x.max() - x.min()),
)
#print(case_durations)

## Let's verify we have cases with duration 0
min_case_duration = case_durations['Duration'].min()
max_case_duration = case_durations['Duration'].max()
mean_case_duration = case_durations['Duration'].mean()

print("Min Case Duration: {}\nMax Case Duration: {}\nMean Case Duration: {}".format(min_case_duration, max_case_duration, mean_case_duration))

filtered_log = pm4py.filter_case_performance(log_df, 0, 0)

#print(len(log_df))
#print(len(filtered_log['case:concept:name'].unique()))

print("Given {} total cases in the log we have {} cases that comply with the applied filter".format(len(log_df['case:concept:name'].unique()), len(filtered_log['case:concept:name'].unique())))

## Let's verify they are all noise

variants = pm4py.get_variants(filtered_log)

print(variants) # Not all of them are noise, they incldue valid traces getting the end like ('Create Fine', 'Payment')

## Let's filter on cases with duration 0 and not ending with a Payment activity

filtered_log = pm4py.filter_variants(log_df, [('Create Fine', 'Send Fine')], retain=True)
filtered_log = pm4py.filter_case_performance(filtered_log, 0, 0)
variants = pm4py.get_variants(filtered_log)
print(variants)

## Let's remove this log segment from the total event log 
### we use pandas functions to get the difference between data frames
### pm4py unfortunately offers very limited options for set operations with event logs 

#log_df_diff = log_df.compare(filtered_log) # working only if the dataframe have the same index
log_df = pd.concat([log_df,filtered_log]).drop_duplicates(keep=False)

num_events = len(log_df)
num_cases = len(log_df['case:concept:name'].unique())
print("Number of events: {}\nNumber of cases: {}".format(num_events, num_cases))

# Incomplete cases

## Let's consider incomplete all cases not ending with a legal end activity like Payment or Send for Credit Collection

filtered_log = pm4py.filter_end_activities(log_df, ['Payment', 'Send for Credit Collection', 'Send Appeal to Prefecture', 'Appeal to Judge'])
                                           
print("Given {} total cases in the log we have {} cases that comply with the applied filter".format(len(log_df['case:concept:name'].unique()), len(filtered_log['case:concept:name'].unique())))
#print("The cycle time of the entire log is {} while the cycle time of the cases that comply with the applied filter is {}".format(cycle_time_log, cycle_time_filtered_log))

## Let's filter traces by attribute value
### we know 'Send Appeal to Prefecture' and 'Appeal to Judge' can be considered a legal end activity only if the value of the 'dismissal' attribute is equal to '#' or 'G' respectively 

filtered_log_att = pm4py.filter_end_activities(log_df, ['Send Appeal to Prefecture', 'Appeal to Judge'])
filtered_log_att = pm4py.filter_trace_attribute_values(filtered_log_att, 'dismissal', ['#', 'G'])

print("Given {} total cases in the log we have {} cases that comply with the applied filter".format(len(filtered_log['case:concept:name'].unique()), len(filtered_log_att['case:concept:name'].unique())))

## Let's merge the log segments we obtained 

filtered_log = pd.concat([filtered_log,filtered_log_att])

num_events = len(filtered_log)
num_cases = len(filtered_log['case:concept:name'].unique())
print("Number of events: {}\nNumber of cases: {}".format(num_events, num_cases))

## let's compute case duration for the filtered log 

case_durations_f = filtered_log.groupby('case:concept:name').agg(\
Events=('case:concept:name', 'count'),\
# Multiple aggregations of the same column using pandas ...
FirstOccurence=('time:timestamp', lambda x: x.min()),
LastOccurence=('time:timestamp', lambda x: x.max()),
Duration=('time:timestamp', lambda x: x.max() - x.min()),
)

min_case_duration_f = case_durations_f['Duration'].min()
max_case_duration_f = case_durations_f['Duration'].max()
mean_case_duration_f = case_durations_f['Duration'].mean()

print("TOTAL event log \nMin Case Duration: {}\nMax Case Duration: {}\nMean Case Duration: {}".format(min_case_duration, max_case_duration, mean_case_duration))

print("FILTERED event log \nMin Case Duration: {}\nMax Case Duration: {}\nMean Case Duration: {}".format(min_case_duration_f, max_case_duration_f, mean_case_duration_f))

# Summarizing 

## Let's get the variants of the filtered log

variants = pm4py.get_variants(filtered_log)
#print(variants)
variants_df = pd.DataFrame.from_dict(variants, orient='index', columns=['Count'])
# create a new column with index values
#variants_df['Variant'] = variants_df.index
variants_df = variants_df.reset_index()
variants_df = variants_df.rename(columns={'index': 'Variant'})
variants_df = variants_df.sort_values(by=['Count'], ascending=False)
variants_df = variants_df.reset_index(drop=True)
variants_df

# Commented out IPython magic to ensure Python compatibility.
## Let's plot the PDF 

# %matplotlib inline
import numpy as np
import matplotlib.pyplot as plt
import math
  
data= variants_df['Count'].head(50)

# getting data of the histogram
count, bins_count = np.histogram(data, bins=50)
  
# finding the PDF of the histogram using count values
pdf = count / sum(count)
  
# using numpy np.cumsum to calculate the CDF
# We can also find using the PDF values by looping and adding
cdf = np.cumsum(pdf)
  
# plotting PDF and CDF
plt.plot(bins_count[1:], pdf, color="red", label="PDF")
plt.plot(bins_count[1:], cdf, label="CDF")
plt.legend()

## Let's extract the top k variants

filtered_log = pm4py.filter_variants_top_k(filtered_log, 10)

num_events = len(filtered_log)
num_cases = len(filtered_log['case:concept:name'].unique())
print("Number of events: {}\nNumber of cases: {}".format(num_events, num_cases))

## let's compute case duration for the filtered log 

case_durations_f = filtered_log.groupby('case:concept:name').agg(\
Events=('case:concept:name', 'count'),\
# Multiple aggregations of the same column using pandas ...
FirstOccurence=('time:timestamp', lambda x: x.min()),
LastOccurence=('time:timestamp', lambda x: x.max()),
Duration=('time:timestamp', lambda x: x.max() - x.min()),
)

min_case_duration_f = case_durations_f['Duration'].min()
max_case_duration_f = case_durations_f['Duration'].max()
mean_case_duration_f = case_durations_f['Duration'].mean()

print("TOTAL event log \nMin Case Duration: {}\nMax Case Duration: {}\nMean Case Duration: {}".format(min_case_duration, max_case_duration, mean_case_duration))

print("FILTERED event log \nMin Case Duration: {}\nMax Case Duration: {}\nMean Case Duration: {}".format(min_case_duration_f, max_case_duration_f, mean_case_duration_f))